{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Extractive Text Summarisation was based on the links below:\n",
    "* https://www.mygreatlearning.com/blog/text-summarization-in-python/#Approaches%20used%20for%20Text%20Summarization\n",
    "* https://affine.ai/how-to-build-a-legal-document-summarizer/\n",
    "* https://medium.com/data-science-in-your-pocket/text-summarization-using-textrank-in-nlp-4bce52c5b390\n",
    "* https://colab.research.google.com/github/dipanjanS/nlp_workshop_odsc19/blob/master/Module05%20-%20NLP%20Applications/Project06%20-%20Text%20Summarization.ipynb#scrollTo=QLjP9KgbFUNi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation - Rouge and Bleu (Ignore Bleu as Bleu is used for Machine Translation)\n",
    "* Difference between Rouge and Bleu: https://stackoverflow.com/questions/38045290/text-summarization-evaluation-bleu-vs-rouge#:~:text=Bleu%20measures%20precision%3A%20how%20much,in%20the%20machine%20generated%20summaries.\n",
    "* Rouge Implementation Python: https://github.com/pltrdy/rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopWords = set(stopwords.words(\"english\"))\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "\n",
    "import spacy\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from scipy import spatial\n",
    "from scipy.sparse.linalg import svds\n",
    "import networkx as nx\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import rouge\n",
    "from rouge import Rouge\n",
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CUAD\n",
    "# contracts_cuad = pd.read_excel('../data/contract_new.xlsx')\n",
    "# contracts_cuad['content'] = contracts_cuad['content'].apply(lambda x: x.lower())\n",
    "# contracts_cuad.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contract</th>\n",
       "      <th>content</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To amend the Public Health Service Act to esta...</td>\n",
       "      <td>section 1. short title. this act may be cited ...</td>\n",
       "      <td>border hospital survival and illegal immigrant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To amend the Richard B. Russell National Schoo...</td>\n",
       "      <td>section 1. short title. this act may be cited ...</td>\n",
       "      <td>farm to school improvements act of 2010 - amen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A bill to amend title 38, United States Code, ...</td>\n",
       "      <td>section 1. short title. this act may be cited ...</td>\n",
       "      <td>persian gulf war illness compensation act of 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A bill to provide for additional outreach and ...</td>\n",
       "      <td>section 1. short title. this act may be cited ...</td>\n",
       "      <td>medicare part d outreach and enrollment enhanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To amend the Internal Revenue Code of 1986 to ...</td>\n",
       "      <td>section 1. short title. this act may be cited ...</td>\n",
       "      <td>seniors' retirement recovery act of 2002 - ame...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            contract  \\\n",
       "0  To amend the Public Health Service Act to esta...   \n",
       "1  To amend the Richard B. Russell National Schoo...   \n",
       "2  A bill to amend title 38, United States Code, ...   \n",
       "3  A bill to provide for additional outreach and ...   \n",
       "4  To amend the Internal Revenue Code of 1986 to ...   \n",
       "\n",
       "                                             content  \\\n",
       "0  section 1. short title. this act may be cited ...   \n",
       "1  section 1. short title. this act may be cited ...   \n",
       "2  section 1. short title. this act may be cited ...   \n",
       "3  section 1. short title. this act may be cited ...   \n",
       "4  section 1. short title. this act may be cited ...   \n",
       "\n",
       "                                             summary  \n",
       "0  border hospital survival and illegal immigrant...  \n",
       "1  farm to school improvements act of 2010 - amen...  \n",
       "2  persian gulf war illness compensation act of 2...  \n",
       "3  medicare part d outreach and enrollment enhanc...  \n",
       "4  seniors' retirement recovery act of 2002 - ame...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BillSum\n",
    "billsum_train = pd.read_excel('../data/billsum_train.xlsx')\n",
    "\n",
    "billsum_train['content'] = billsum_train['content'].apply(lambda x: x.lower())\n",
    "billsum_train['summary'] = billsum_train['summary'].apply(lambda x: x.lower())\n",
    "billsum_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = str(billsum_train['content'][0])\n",
    "#print(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize using Avg Sentence Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenise the text\n",
    "words = word_tokenize(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a freq table to keep the score of each word\n",
    "freqTable = dict()\n",
    "for word in words:\n",
    "    if word in stopWords:\n",
    "        continue\n",
    "    if word in freqTable:\n",
    "        freqTable[word] += 1\n",
    "    else:\n",
    "        freqTable[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary to keep the score of each sentence\n",
    "sentences = sent_tokenize(input_text)\n",
    "sentenceValue = dict()\n",
    "for sentence in sentences:\n",
    "    for word, freq in freqTable.items():\n",
    "        if word in sentence:\n",
    "            if sentence in sentenceValue:\n",
    "                sentenceValue[sentence] += freq\n",
    "            else:\n",
    "                sentenceValue[sentence] = freq\n",
    "                \n",
    "sumValue = 0\n",
    "for sentence in sentenceValue:\n",
    "    sumValue += sentenceValue[sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average value of a sentence from the original text\n",
    "avg = int(sumValue/len(sentenceValue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1395dd) and state laws require that, if any individual (whether or not lawfully present in the united states) comes to a hospital and the hospital determines that the individual has an emergency medical condition, the hospital must provide either, within the staff and facilities available at the hospital, for such further medical examination and such treatment as may be required to stabilize the medical condition, or, if appropriate, for transfer of the individual to another medical facility. 249) is amended by adding at the end the following: ``(d)(1) the secretary shall establish and implement a 5-year pilot program under which funds made available under paragraph (6) are used to reimburse providers for items and services described in section 411(b)(1) of the personal responsibility and work opportunity reconciliation act of 1996 (8 u.s.c. 1621(b)(1)) provided in arizona to aliens described in paragraph (3), and to reimburse suppliers of emergency ambulance services furnished to such aliens for which the transportation originates in arizona (where the use of other methods of transportation is contraindicated by the alien's condition), if payment may not be made to reimburse the provider or supplier under any federal program or law other than this subsection (such as title xix of the social security act), any state or local program or law, any group or individual health plan, or any insurance policy. ``(2) as part of the pilot program, in a case in which an alien described in paragraph (3) arrived at a hospital in arizona and the hospital provided for such medical examination and treatment of the alien as the hospital determined was required to stabilize an emergency medical condition (within the meaning of section 1867(e)(1) of the social security act (42 u.s.c. 1395dd(e)(1))), the secretary shall use funds made available under paragraph (6) to reimburse the hospital for any transportation costs paid by the hospital to return the alien to the united states border, if-- ``(a) the hospital requested the attorney general to take the alien into custody after such stabilization; ``(b) such request was denied within 24 hours after its receipt, or the attorney general gave no response to it within such period; and ``(c) the hospital determined that discharging the alien without providing for such transportation might pose a threat to the health or safety of the alien (or, with respect to a pregnant alien, the health or safety of the alien or her unborn child). ``(3) an alien is described in this paragraph if the alien-- ``(a) is not lawfully present in the united states and not detained by any federal, state, or local law enforcement authority; or ``(b) is paroled into the united states under section 212(d)(5) of the immigration and nationality act (8 u.s.c. ``(5) nothing in this subsection shall be construed to authorize any reduction in the funds payable to any person under any federal program or law other than this subsection (such as title xix of the social security act), any state or local program or law, any group or individual health plan, or any insurance policy. ``(6) to the extent provided in appropriations acts, from amounts made available to the immigration and naturalization service for enforcement and border affairs for each of the 5 fiscal years following the fiscal year in which the border hospital survival and illegal immigrant care act is enacted, the attorney general may transfer to the health resources and services administration of the department of health and human services such amounts as may be necessary to carry out this subsection, not to exceed $50,000,000 for each such year. \n"
     ]
    }
   ],
   "source": [
    "# Storing sentences into our summary\n",
    "summary_ass = ''\n",
    "summary_list = []\n",
    "for sentence in sentences:\n",
    "    if (sentence in sentenceValue) and (sentenceValue[sentence]>(1.2*avg)):\n",
    "        summary_list.append(sentence)\n",
    "        summary_ass += sentence + ' '\n",
    "        \n",
    "print(summary_ass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "border hospital survival and illegal immigrant care act - amends the public health service act to direct the secretary of health and human services to establish a five-year pilot program of health care provider reimbursement for the costs associated with providing emergency medical and ambulance services in arizona to: (1) illegal aliens who are not detained by any federal, state, or local law enforcement authority. or (2) aliens paroled into the united states for less than one year to receive emergency medical treatment.\n"
     ]
    }
   ],
   "source": [
    "print(billsum_train['summary'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences))\n",
    "print(len(summary_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rouge Implementation\n",
    "rouge = Rouge()\n",
    "scores_ass = rouge.get_scores(summary_ass, billsum_train['summary'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge-1:\n",
      "precision: 0.2033195020746888\n",
      "recall: 0.765625\n",
      "f1-score: 0.3213114720937383\n",
      "\n",
      "rouge-2:\n",
      "precision: 0.0625\n",
      "recall: 0.3625\n",
      "f1-score: 0.10661764455017307\n",
      "\n",
      "rouge-l:\n",
      "precision: 0.17012448132780084\n",
      "recall: 0.640625\n",
      "f1-score: 0.26885245570029564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for score, f1 in scores_ass[0].items():\n",
    "    print(f\"{score}:\")\n",
    "    print(f\"precision: {f1['p']}\")\n",
    "    print(f\"recall: {f1['r']}\")\n",
    "    print(f\"f1-score: {f1['f']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextRank Algorithm (Using PageRank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuations and special characters\n",
    "sentences_clean=[re.sub(r'[^\\w\\s]','',sentence.lower()) for sentence in sentences]\n",
    "\n",
    "# remove stopwords\n",
    "sentence_tokens=[[words for words in sentence.split(' ') if words not in stopWords] for sentence in sentences_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word embedding\n",
    "w2v=Word2Vec(sentence_tokens, vector_size=1, min_count=1, epochs=1000)\n",
    "\n",
    "sentence_embeddings=[[w2v.wv[word][0] for word in words] for words in sentence_tokens]\n",
    "max_len=max([len(tokens) for tokens in sentence_tokens])\n",
    "\n",
    "# padding\n",
    "sentence_embeddings=[np.pad(embedding,(0,max_len-len(embedding)),'constant') for embedding in sentence_embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(u, v):\n",
    "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a matrix of NxN where N is the total number of sentences in the text\n",
    "similarity_matrix = np.zeros([len(sentence_tokens), len(sentence_tokens)])\n",
    "\n",
    "# calculate the similarity between every 2 pairs of sentences\n",
    "for i,row_embedding in enumerate(sentence_embeddings):\n",
    "    for j,column_embedding in enumerate(sentence_embeddings):\n",
    "        similarity_matrix[i][j]=1-spatial.distance.cosine(row_embedding,column_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert similarity matrix to a network/graph\n",
    "nx_graph = nx.from_numpy_array(similarity_matrix)\n",
    "\n",
    "#apply pagerank\n",
    "scores = nx.pagerank(nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a sorted dictionary with sentences and their pagerank value. pick the top 4 sentences\n",
    "top_sentence={sentence:scores[index] for index,sentence in enumerate(sentences)}\n",
    "top=dict(sorted(top_sentence.items(), key=lambda x: x[1], reverse=True)[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the top 4 sentences\n",
    "summary_tr = ''\n",
    "for sent in sentences:\n",
    "    if sent in top.keys():\n",
    "        summary_tr += sent + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2) the immigration and naturalization service does not take into custody all aliens who are unlawfully present in the united states. 1182(d)(5)) for less than one year in order to receive treatment for an emergency medical condition. each report shall contain at least the following information: ``(a) the number of aliens to whom assistance was rendered for which payment was made under this subsection during the previous year. ``(e) the feasibility and estimated cost of expanding the pilot program to items and services provided anywhere in the southwest border region of the united states. \n"
     ]
    }
   ],
   "source": [
    "print(summary_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge-1:\n",
      "precision: 0.375\n",
      "recall: 0.421875\n",
      "f1-score: 0.3970588185467128\n",
      "\n",
      "rouge-2:\n",
      "precision: 0.12087912087912088\n",
      "recall: 0.1375\n",
      "f1-score: 0.12865496578092422\n",
      "\n",
      "rouge-l:\n",
      "precision: 0.2916666666666667\n",
      "recall: 0.328125\n",
      "f1-score: 0.30882352442906574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Rouge Implementation\n",
    "rouge = Rouge()\n",
    "scores_tr = rouge.get_scores(summary_tr, billsum_train['summary'][0])\n",
    "\n",
    "for score, f1 in scores_tr[0].items():\n",
    "    print(f\"{score}:\")\n",
    "    print(f\"precision: {f1['p']}\")\n",
    "    print(f\"recall: {f1['r']}\")\n",
    "    print(f\"f1-score: {f1['f']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['section short title',\n",
       "       'act may cited border hospital survival illegal immigrant care act',\n",
       "       'sec'], dtype='<U461')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalising text\n",
    "sentences = sent_tokenize(input_text)\n",
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    # tokenize document\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stopWords]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "normalize_corpus = np.vectorize(normalize_document)\n",
    "\n",
    "norm_sentences = normalize_corpus(sentences)\n",
    "norm_sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(215, 30)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>absorb</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acts</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adding</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>administration</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>affairs</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alien</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aliens</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ambulance</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amended</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0     1    2    3    4     5     6    7     8     9   ...  \\\n",
       "absorb          0.0  0.00  0.0  0.0  0.0  0.00  0.00  0.0  0.26  0.00  ...   \n",
       "act             0.0  0.42  0.0  0.0  0.0  0.00  0.36  0.0  0.00  0.18  ...   \n",
       "acts            0.0  0.00  0.0  0.0  0.0  0.00  0.00  0.0  0.00  0.00  ...   \n",
       "adding          0.0  0.00  0.0  0.0  0.0  0.00  0.00  0.0  0.00  0.00  ...   \n",
       "administration  0.0  0.00  0.0  0.0  0.0  0.00  0.00  0.0  0.00  0.00  ...   \n",
       "affairs         0.0  0.00  0.0  0.0  0.0  0.00  0.00  0.0  0.00  0.00  ...   \n",
       "alien           0.0  0.00  0.0  0.0  0.0  0.00  0.00  0.0  0.00  0.00  ...   \n",
       "aliens          0.0  0.00  0.0  0.0  0.0  0.25  0.00  0.0  0.17  0.00  ...   \n",
       "ambulance       0.0  0.00  0.0  0.0  0.0  0.00  0.00  0.0  0.00  0.00  ...   \n",
       "amended         0.0  0.00  0.0  0.0  0.0  0.00  0.00  0.0  0.00  0.00  ...   \n",
       "\n",
       "                 20   21    22    23    24   25   26    27    28   29  \n",
       "absorb          0.0  0.0  0.00  0.00  0.00  0.0  0.0  0.00  0.00  0.0  \n",
       "act             0.0  0.0  0.00  0.00  0.00  0.0  0.0  0.11  0.08  0.0  \n",
       "acts            0.0  0.0  0.00  0.00  0.00  0.0  0.0  0.00  0.15  0.0  \n",
       "adding          0.0  0.0  0.00  0.00  0.00  0.0  0.0  0.00  0.00  0.0  \n",
       "administration  0.0  0.0  0.00  0.00  0.00  0.0  0.0  0.00  0.15  0.0  \n",
       "affairs         0.0  0.0  0.00  0.00  0.00  0.0  0.0  0.00  0.15  0.0  \n",
       "alien           0.0  0.0  0.00  0.00  0.39  0.0  0.0  0.00  0.00  0.0  \n",
       "aliens          0.0  0.0  0.19  0.58  0.00  0.0  0.0  0.00  0.00  0.0  \n",
       "ambulance       0.0  0.0  0.00  0.00  0.00  0.0  0.0  0.00  0.00  0.0  \n",
       "amended         0.0  0.0  0.00  0.00  0.00  0.0  0.0  0.00  0.00  0.0  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature extraction\n",
    "tv = TfidfVectorizer(min_df=0., max_df=1., use_idf=True)\n",
    "dt_matrix = tv.fit_transform(norm_sentences)\n",
    "dt_matrix = dt_matrix.toarray()\n",
    "\n",
    "vocab = tv.get_feature_names()\n",
    "td_matrix = dt_matrix.T\n",
    "print(td_matrix.shape)\n",
    "pd.DataFrame(np.round(td_matrix, 2), index=vocab).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_rank_svd(matrix, singular_count=2):\n",
    "    u, s, vt = svds(matrix, k=singular_count)\n",
    "    return u, s, vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(215, 3) (3,) (3, 30)\n"
     ]
    }
   ],
   "source": [
    "num_sentences = 8\n",
    "num_topics = 3\n",
    "\n",
    "u, s, vt = low_rank_svd(td_matrix, singular_count=num_topics)  \n",
    "print(u.shape, s.shape, vt.shape)\n",
    "term_topic_mat, singular_values, topic_document_mat = u, s, vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove singular values below threshold                                         \n",
    "sv_threshold = 0.5\n",
    "min_sigma_value = max(singular_values) * sv_threshold\n",
    "singular_values[singular_values < min_sigma_value] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.28447139e-01, 3.79549888e-01, 1.00000000e+00, 2.48713951e-16,\n",
       "       1.14872810e-01, 2.76577898e-01, 6.60026826e-01, 5.82696370e-01,\n",
       "       2.23215803e-01, 7.48100788e-01, 1.60999653e-16, 2.09484052e-01,\n",
       "       1.00000000e+00, 3.49695771e-01, 8.34256991e-01, 3.75022422e-01,\n",
       "       5.39183298e-01, 6.47729445e-01, 5.18552492e-01, 4.90260772e-01,\n",
       "       3.56344363e-01, 1.77027702e-01, 2.60759892e-01, 2.16161894e-01,\n",
       "       2.50751900e-01, 1.32702058e-01, 2.85298278e-01, 3.96789511e-01,\n",
       "       3.94045729e-01, 2.85002073e-16])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salience_scores = np.sqrt(np.dot(np.square(singular_values), \n",
    "                                 np.square(topic_document_mat)))\n",
    "salience_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_sentence_indices = (-salience_scores).argsort()[:num_sentences]\n",
    "top_sentence_indices.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sec. (3) section 1867 of the social security act (42 u.s.c. 1395dd) and state laws require that, if any individual (whether or not lawfully present in the united states) comes to a hospital and the hospital determines that the individual has an emergency medical condition, the hospital must provide either, within the staff and facilities available at the hospital, for such further medical examination and such treatment as may be required to stabilize the medical condition, or, if appropriate, for transfer of the individual to another medical facility. (5) the southwest border region has been designated as a health professional shortage area under section 332 of the public health service act (42 u.s.c. sec. section 322 of the public health service act (42 u.s.c. 1621(b)(1)) provided in arizona to aliens described in paragraph (3), and to reimburse suppliers of emergency ambulance services furnished to such aliens for which the transportation originates in arizona (where the use of other methods of transportation is contraindicated by the alien's condition), if payment may not be made to reimburse the provider or supplier under any federal program or law other than this subsection (such as title xix of the social security act), any state or local program or law, any group or individual health plan, or any insurance policy. ``(2) as part of the pilot program, in a case in which an alien described in paragraph (3) arrived at a hospital in arizona and the hospital provided for such medical examination and treatment of the alien as the hospital determined was required to stabilize an emergency medical condition (within the meaning of section 1867(e)(1) of the social security act (42 u.s.c.\n"
     ]
    }
   ],
   "source": [
    "summary_lsa = ' '.join(np.array(sentences)[top_sentence_indices])\n",
    "print(summary_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge-1:\n",
      "precision: 0.22627737226277372\n",
      "recall: 0.484375\n",
      "f1-score: 0.30845770710229947\n",
      "\n",
      "rouge-2:\n",
      "precision: 0.038135593220338986\n",
      "recall: 0.1125\n",
      "f1-score: 0.05696202153501067\n",
      "\n",
      "rouge-l:\n",
      "precision: 0.17518248175182483\n",
      "recall: 0.375\n",
      "f1-score: 0.23880596580876717\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Rouge Implementation\n",
    "rouge = Rouge()\n",
    "scores_lsa = rouge.get_scores(summary_lsa, billsum_train['summary'][0])\n",
    "\n",
    "for score, f1 in scores_lsa[0].items():\n",
    "    print(f\"{score}:\")\n",
    "    print(f\"precision: {f1['p']}\")\n",
    "    print(f\"recall: {f1['r']}\")\n",
    "    print(f\"f1-score: {f1['f']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KL-Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Luhn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
